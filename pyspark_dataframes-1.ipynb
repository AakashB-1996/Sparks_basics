{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/26 14:57:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/26 14:57:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "/Users/aakashbolisetty/.pyenv/versions/3.7.5/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Dataframe-1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://aakashs-mbp.lan:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe-1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1117fe890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset into a pyspark dtaaframe\n",
    "\n",
    "df_pyspark=spark.read.csv('employees.csv',header = True,inferSchema=True) \n",
    "#Inferschema looks at the values and sets the datatypes accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Phone: integer (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Skills: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Check the Schema (Similar to info in pandas)\n",
    "\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'FirstName',\n",
       " 'LastName',\n",
       " 'Department',\n",
       " 'Phone',\n",
       " 'Address',\n",
       " 'Salary',\n",
       " 'Skills']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To get all column names\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=1, FirstName='Luke', LastName='Phillip', Department='Sales', Phone=1234567890, Address='1st Address, Miami', Salary=52000, Skills='Online Sales'),\n",
       " Row(ID=2, FirstName='Jack', LastName='Darren', Department='IT', Phone=1234567891, Address='2nd Address, Miami', Salary=52200, Skills='Networking'),\n",
       " Row(ID=3, FirstName='Ken', LastName='Wood', Department='IT', Phone=1234567892, Address='3rd Address, Miami', Salary=58000, Skills='Python, Java')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List format output for top n rows\n",
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|FirstName|LastName|\n",
      "+---------+--------+\n",
      "|     Luke| Phillip|\n",
      "|     Jack|  Darren|\n",
      "|      Ken|    Wood|\n",
      "|     John|  Wilson|\n",
      "|    Emily|  Larson|\n",
      "|     Anna|Sullivan|\n",
      "|  Richard|   Smith|\n",
      "|   Ronnie|   Moore|\n",
      "|      Ron|   Drake|\n",
      "|    Wayne|  Barker|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Select certain columns\n",
    "#SLICING IS NOT POSSIBLE TO SELECT COLUMNS\n",
    "df_pyspark.select(['FirstName','LastName']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID', 'int'),\n",
       " ('FirstName', 'string'),\n",
       " ('LastName', 'string'),\n",
       " ('Department', 'string'),\n",
       " ('Phone', 'int'),\n",
       " ('Address', 'string'),\n",
       " ('Salary', 'int'),\n",
       " ('Skills', 'string')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/26 15:08:15 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+---------+--------+----------+------------------+-------------------+-----------------+---------------+\n",
      "|summary|                ID|FirstName|LastName|Department|             Phone|            Address|           Salary|         Skills|\n",
      "+-------+------------------+---------+--------+----------+------------------+-------------------+-----------------+---------------+\n",
      "|  count|                10|       10|      10|        10|                10|                 10|               10|             10|\n",
      "|   mean|               5.5|     null|    null|      null|    1.2345678945E9|               null|          55240.0|           null|\n",
      "| stddev|3.0276503540974917|     null|    null|      null|3.0276503540974917|               null|3744.685122499176|           null|\n",
      "|    min|                 1|     Anna|  Barker|        IT|        1234567890|10th Address, Miami|            49000|   Facebook Ads|\n",
      "|    max|                10|    Wayne|    Wood|     Sales|        1234567899| 9th Address, Miami|            60000|Warehouse Mgmt.|\n",
      "+-------+------------------+---------+--------+----------+------------------+-------------------+-----------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding columns in the dataframe by operating on another column\n",
    "\n",
    "df_pyspark = df_pyspark.withColumn('Salary+1000',df_pyspark['Salary']+1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+----------+-------------------+------+---------------+-----------+\n",
      "| ID|FirstName|LastName|Department|     Phone|            Address|Salary|         Skills|Salary+1000|\n",
      "+---+---------+--------+----------+----------+-------------------+------+---------------+-----------+\n",
      "|  1|     Luke| Phillip|     Sales|1234567890| 1st Address, Miami| 53000|   Online Sales|      54000|\n",
      "|  2|     Jack|  Darren|        IT|1234567891| 2nd Address, Miami| 53200|     Networking|      54200|\n",
      "|  3|      Ken|    Wood|        IT|1234567892| 3rd Address, Miami| 59000|   Python, Java|      60000|\n",
      "|  4|     John|  Wilson| Marketing|1234567893| 4th Address, Miami| 59700|   Facebook Ads|      60700|\n",
      "|  5|    Emily|  Larson| Marketing|1234567894| 5th Address, Miami| 61000|  Instagram Ads|      62000|\n",
      "|  6|     Anna|Sullivan|     Sales|1234567895| 6th Address, Miami| 55000|In-Person Sales|      56000|\n",
      "|  7|  Richard|   Smith| Logistics|1234567896| 7th Address, Miami| 57000|Warehouse Mgmt.|      58000|\n",
      "|  8|   Ronnie|   Moore|     Sales|1234567897| 8th Address, Miami| 50000|   Online Sales|      51000|\n",
      "|  9|      Ron|   Drake|        IT|1234567898| 9th Address, Miami| 54000|  Linux Servers|      55000|\n",
      "| 10|    Wayne|  Barker| Logistics|1234567899|10th Address, Miami| 60500|Product Loading|      61500|\n",
      "+---+---------+--------+----------+----------+-------------------+------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show() ## The column can get changed if you keep the same column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+----------+-------------------+------+---------------+\n",
      "| ID|FirstName|LastName|Department|     Phone|            Address|Salary|         Skills|\n",
      "+---+---------+--------+----------+----------+-------------------+------+---------------+\n",
      "|  1|     Luke| Phillip|     Sales|1234567890| 1st Address, Miami| 53000|   Online Sales|\n",
      "|  2|     Jack|  Darren|        IT|1234567891| 2nd Address, Miami| 53200|     Networking|\n",
      "|  3|      Ken|    Wood|        IT|1234567892| 3rd Address, Miami| 59000|   Python, Java|\n",
      "|  4|     John|  Wilson| Marketing|1234567893| 4th Address, Miami| 59700|   Facebook Ads|\n",
      "|  5|    Emily|  Larson| Marketing|1234567894| 5th Address, Miami| 61000|  Instagram Ads|\n",
      "|  6|     Anna|Sullivan|     Sales|1234567895| 6th Address, Miami| 55000|In-Person Sales|\n",
      "|  7|  Richard|   Smith| Logistics|1234567896| 7th Address, Miami| 57000|Warehouse Mgmt.|\n",
      "|  8|   Ronnie|   Moore|     Sales|1234567897| 8th Address, Miami| 50000|   Online Sales|\n",
      "|  9|      Ron|   Drake|        IT|1234567898| 9th Address, Miami| 54000|  Linux Servers|\n",
      "| 10|    Wayne|  Barker| Logistics|1234567899|10th Address, Miami| 60500|Product Loading|\n",
      "+---+---------+--------+----------+----------+-------------------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Drop the column\n",
    "df_pyspark = df_pyspark.drop('Salary+1000')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+---------+----------+-------------------+------+---------------+\n",
      "| ID|FirstName|LastName|     Dept|     Phone|            Address|Salary|         Skills|\n",
      "+---+---------+--------+---------+----------+-------------------+------+---------------+\n",
      "|  1|     Luke| Phillip|    Sales|1234567890| 1st Address, Miami| 53000|   Online Sales|\n",
      "|  2|     Jack|  Darren|       IT|1234567891| 2nd Address, Miami| 53200|     Networking|\n",
      "|  3|      Ken|    Wood|       IT|1234567892| 3rd Address, Miami| 59000|   Python, Java|\n",
      "|  4|     John|  Wilson|Marketing|1234567893| 4th Address, Miami| 59700|   Facebook Ads|\n",
      "|  5|    Emily|  Larson|Marketing|1234567894| 5th Address, Miami| 61000|  Instagram Ads|\n",
      "|  6|     Anna|Sullivan|    Sales|1234567895| 6th Address, Miami| 55000|In-Person Sales|\n",
      "|  7|  Richard|   Smith|Logistics|1234567896| 7th Address, Miami| 57000|Warehouse Mgmt.|\n",
      "|  8|   Ronnie|   Moore|    Sales|1234567897| 8th Address, Miami| 50000|   Online Sales|\n",
      "|  9|      Ron|   Drake|       IT|1234567898| 9th Address, Miami| 54000|  Linux Servers|\n",
      "| 10|    Wayne|  Barker|Logistics|1234567899|10th Address, Miami| 60500|Product Loading|\n",
      "+---+---------+--------+---------+----------+-------------------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Rename the column\n",
    "df_pyspark=df_pyspark.withColumnRenamed(\"Department\",'Dept')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.7.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
