{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/26 19:38:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/26 19:38:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/12/26 19:38:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/12/26 19:38:33 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/12/26 19:38:33 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "/Users/aakashbolisetty/.pyenv/versions/3.7.5/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('groupagg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+----------+-------------------+------+---------------+\n",
      "| ID|FirstName|LastName|Department|     Phone|            Address|Salary|         Skills|\n",
      "+---+---------+--------+----------+----------+-------------------+------+---------------+\n",
      "|  1|     Luke| Phillip|     Sales|1234567890| 1st Address, Miami| 52000|   Online Sales|\n",
      "|  2|     Jack|  Darren|        IT|1234567891| 2nd Address, Miami| 52200|     Networking|\n",
      "|  3|      Ken|    Wood|        IT|1234567892| 3rd Address, Miami| 58000|   Python, Java|\n",
      "|  4|     John|  Wilson| Marketing|1234567893| 4th Address, Miami| 58700|   Facebook Ads|\n",
      "|  5|    Emily|  Larson| Marketing|1234567894| 5th Address, Miami| 60000|  Instagram Ads|\n",
      "|  6|     Anna|Sullivan|     Sales|1234567895| 6th Address, Miami| 54000|In-Person Sales|\n",
      "|  7|  Richard|   Smith| Logistics|1234567896| 7th Address, Miami| 56000|Warehouse Mgmt.|\n",
      "|  8|   Ronnie|   Moore|     Sales|1234567897| 8th Address, Miami| 49000|   Online Sales|\n",
      "|  9|      Ron|   Drake|        IT|1234567898| 9th Address, Miami| 53000|  Linux Servers|\n",
      "| 10|    Wayne|  Barker| Logistics|1234567899|10th Address, Miami| 59500|Product Loading|\n",
      "+---+---------+--------+----------+----------+-------------------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('employees.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|sum(Salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|     155000|\n",
      "| Marketing|     118700|\n",
      "|        IT|     163200|\n",
      "| Logistics|     115500|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Group by\n",
    "df_pyspark.groupBy('Department').sum('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|Department|       avg(Salary)|\n",
      "+----------+------------------+\n",
      "|     Sales|51666.666666666664|\n",
      "| Marketing|           59350.0|\n",
      "|        IT|           54400.0|\n",
      "| Logistics|           57750.0|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Department').mean('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|Department|count|\n",
      "+----------+-----+\n",
      "|     Sales|    3|\n",
      "| Marketing|    2|\n",
      "|        IT|    3|\n",
      "| Logistics|    2|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Department').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|     552400|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.7.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
